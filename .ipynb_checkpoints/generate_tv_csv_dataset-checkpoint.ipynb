{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Use sidereel.py and tvseriesfinale.py to create tv.csv\n",
    "##Output: tv.csv (tv dataset to be used for analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _py_helpers.sidereel #for show_list(title, genre, tag) and show_titles(title only) lists \n",
    "import _py_helpers.tvseriesfinale #for canceled_shows(title, network, status) and title(title only) lists\n",
    "import _py_helpers.wikipediastate\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersect(a, b):\n",
    "     return list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sidereel_titles = _py_helpers.sidereel.show_titles\n",
    "finale_titles = _py_helpers.tvseriesfinale.title\n",
    "inter = intersect(sidereel_titles, finale_titles) #show dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shows = [[show] for show in inter]\n",
    "shows_cols = ['Title']\n",
    "finale_df = pd.DataFrame(shows, columns=shows_cols) #show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_list_norm = [] #normalized show title\n",
    "for row in _py_helpers.sidereel.show_list:\n",
    "    temp = []\n",
    "    temp.append(row[0])\n",
    "    temp.append(row[1])\n",
    "    temp.append(row[2])\n",
    "    temp.append(''.join(letter for letter in row[0] if letter.isalnum()).lower())\n",
    "    show_list_norm.append(temp)\n",
    "sidereel_cols = ['Title', 'Genre', 'Tag', 'Title_Norm']\n",
    "sidereel_df = pd.DataFrame(show_list_norm, columns=sidereel_cols) #normalized show dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_genre_tag = pd.merge(finale_df, sidereel_df, on='Title', how='left')\n",
    "show_genre_tag = show_genre_tag[show_genre_tag['Title'] != 'Stars Earn Stripe']\n",
    "show_genre_tag.sort(['Title', 'Genre'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Webscraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = show_genre_tag['Tag'].tolist()\n",
    "url = 'http://www.sidereel.com'\n",
    "sidereel_data = []\n",
    "\n",
    "for i in range(len(tags)):\n",
    "    per = []\n",
    "    response = requests.get(url + tags[i])\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "    main = soup.find(class_ = 'tv-show-card-main')\n",
    "    main_grid = main.find(class_ = 'row grid')\n",
    "    main_grid_status = main_grid.find(class_ = 'country')\n",
    "\n",
    "    #get title\n",
    "    title = soup.find(class_ = 'title').text.strip().encode('utf-8')\n",
    "    per.append(soup.find(class_ = 'title').text.strip().encode('utf-8'))\n",
    "    #get seasons\n",
    "    season = main_grid.find_all('span')[0].text.encode('utf-8')\n",
    "    per.append(main_grid.find_all('span')[0].text.encode('utf-8'))\n",
    "    #get episodes\n",
    "    episode = main_grid.find_all('span')[1].text.encode('utf-8')\n",
    "    per.append(main_grid.find_all('span')[1].text.encode('utf-8'))\n",
    "    #get current_status\n",
    "    try:\n",
    "        current_status = main_grid_status.text.strip('\\n').split(':')[1].encode('utf-8').strip()\n",
    "        per.append(main_grid_status.text.strip('\\n').split(':')[1].encode('utf-8').strip())\n",
    "    except:\n",
    "        per.append('Concluded')\n",
    "    #get runtime\n",
    "    try:\n",
    "        runtime = main_grid.find(class_ = 'duration-data').text.encode('utf-8')\n",
    "        per.append(main_grid.find(class_ = 'duration-data').text.encode('utf-8'))\n",
    "    except:\n",
    "        try:\n",
    "            runtime = main_grid.find(class_ = 'airtime content airs').text.split('(')[1].split(')')[0].encode('utf-8')\n",
    "            per.append(main_grid.find(class_ = 'airtime content airs').text.split('(')[1].split(')')[0].encode('utf-8'))\n",
    "        except:\n",
    "            per.append('None')\n",
    "    #get rating\n",
    "    try:\n",
    "        user_rating = str(main.find(class_ = 'rating-group').find_all('meta')[1]).split('\"')[1]\n",
    "        per.append(str(main.find(class_ = 'rating-group').find_all('meta')[1]).split('\"')[1])\n",
    "    except:\n",
    "        per.append(0.00)\n",
    "    \n",
    "    sidereel_data.append(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7133ccccc1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msidereel_data_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Seasons'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Episodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Status'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Duration'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UserRating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msidereel_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msidereel_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msidereel_data_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sidereel data dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "sidereel_data_cols = ['Title', 'Seasons', 'Episodes', 'Status', 'Duration', 'UserRating']\n",
    "sidereel_data_df = pd.DataFrame(sidereel_data, columns=sidereel_data_cols).drop_duplicates() #sidereel data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge title dataset with sidereel data\n",
    "tv_df = pd.merge(show_genre_tag, sidereel_data_df, on='Title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "series_finale = [[show[0], show[1]] for show in _py_helpers.tvseriesfinale.canceled_shows]\n",
    "cols_sf = ['Title', 'Network']\n",
    "series_finale_df = pd.DataFrame(series_finale, columns=cols_sf).drop_duplicates() #finale data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge dataset with finale data\n",
    "tv_df = pd.merge(tv_df, series_finale_df, on='Title', how='left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_state_norm = []\n",
    "for row in _py_helpers.wikipediastate.show_state:\n",
    "    temp = []\n",
    "    temp.append(row[0])\n",
    "    temp.append(row[1])\n",
    "    temp.append(''.join(letter for letter in row[0] if letter.isalnum()).lower())\n",
    "    show_state_norm.append(temp)\n",
    "wiki_cols = ['Title', 'State', 'Title_Norm']\n",
    "wiki_state_df = pd.DataFrame(show_state_norm, columns=wiki_cols) #wikipedia data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv_df = pd.merge(tv_df, wiki_state_df, on='Title_Norm', how='left', suffixes=('_SR', '_Wiki'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv_df = tv_df.where((pd.notnull(tv_df)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tv_df.to_csv('data/tv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
